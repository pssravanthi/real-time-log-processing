# Real-Time Log Processing Pipeline

## ğŸ“Œ Project Overview
This project implements a **real-time log processing pipeline** using **Kafka, Spark, FastAPI, and Snowflake**. It enables:
- **Streaming log generation** via Kafka.
- **Real-time anomaly detection** using Spark.
- **Storage & retrieval** via Snowflake.
- **REST API exposure** using FastAPI.
- **Monitoring** via Prometheus & Grafana.

## ğŸ› ï¸ Tech Stack
- **Apache Kafka** â†’ Log streaming.
- **Apache Spark** â†’ Real-time processing.
- **FastAPI** â†’ REST API for log retrieval.
- **Snowflake** â†’ Cloud data storage.
- **Docker & Kubernetes** â†’ Containerized deployment.
- **Prometheus & Grafana** â†’ Monitoring & visualization.

## ğŸš€ How to Run

### 1ï¸âƒ£ Start Kafka & Zookeeper
```bash
docker-compose up -d
```

### 2ï¸âƒ£ Run Log Producer (Generates Logs)
```bash
python log_producer.py
```

### 3ï¸âƒ£ Run Spark Processing (Detects Anomalies)
```bash
python log_processor.py
```

### 4ï¸âƒ£ Run API (Exposes Processed Logs)
```bash
uvicorn log_api:app --reload
```

### 5ï¸âƒ£ Run Monitoring Services
```bash
docker run -p 9090:9090 -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus
docker run -p 3000:3000 grafana/grafana
```

## ğŸ“¡ API Endpoints
- `GET /logs` â†’ Fetch latest processed logs.

## ğŸ”§ Deployment
For production, deploy using **Docker Compose** or **Kubernetes**:
```bash
docker-compose up -d
```
OR
```bash
kubectl apply -f deployment.yaml
```

## ğŸ“Š Monitoring with Grafana
- Open **http://localhost:3000** (Grafana UI)
- Open **http://localhost:9090** (Prometheus Metrics)

## ğŸ“ License
This project is open-source and available under the **MIT License**.
